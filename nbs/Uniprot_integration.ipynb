{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp uniprot_integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integration of Uniprot Data\n",
    "\n",
    "This notebook allows to download Uniprot data and save them in a csv format.  \n",
    "\n",
    "The preprocessed downloaded data will include information about:  \n",
    "- __the preprocessing events__ known for proteins, such as signal peptide, transit peptide, propeptide, chain, peptide;\n",
    "- information on all available in Uniprot __post translational modificatios__, like modified residues (Phosphorylation, Methylation, Acetylation, etc.), Lipidation, Glycosylation, etc.;\n",
    "- information on __sequence similarities__ with other proteins and __the domain(s)__ present in a protein, such as domain, repear, region, motif, etc.;\n",
    "- information on __the secondary and tertiary structure__ of proteins, such as turn, beta strand, helix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify a path to the downloaded from Uniprot DB flat txt file\n",
    "\n",
    "1. Go to the Uniprot website(https://www.uniprot.org/uniprot/), select a needed organism in the \"Popular organisms\" section and click on it.\n",
    "2. Click the \"Download\" button and select \"Text\" format.\n",
    "3. Select the \"Compressed\" radio button and click \"Go\".\n",
    "4. Unzip the downloaded file and specify a path to this file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_downloaded_uniprot = '../testdata/uniprot-filtered-organism__Homo+sapiens+(Human)+[9606]_.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define helper functions to preprocess Uniprot data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def extract_note(string, splitted=False):\n",
    "    \"\"\"\n",
    "    Function to extract information about note of the protein from Uniprot using regular expression\n",
    "    \"\"\"\n",
    "    if not splitted:\n",
    "        regex = r\"\\/note=\\\"(?P<note>.+?)\\\"\"\n",
    "    else:\n",
    "        regex = r\"\\/note=\\\"(?P<note>.*)\"\n",
    "    result = re.findall(regex, string)\n",
    "    return result\n",
    "\n",
    "def extract_note_end(string, has_mark=True):\n",
    "    if has_mark:\n",
    "        regex = r\"FT\\s+(?P<note>.*)\\\"\"\n",
    "    else:\n",
    "        regex = r\"FT\\s+(?P<note>.*)\"\n",
    "    result = re.findall(regex, string)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def resolve_unclear_position(value):\n",
    "    \"\"\"\n",
    "    Replace unclear position of the start/end of the modification defined as '?' with -1 and if it's defined as '?N' \n",
    "    or \">N\" - by removing the '?'/'>'/'<' signs\n",
    "    \"\"\"\n",
    "    # if it's \"1..?\" or \"?..345\" for start or end -> remove -1 that we can filter later\n",
    "    # if it's \"31..?327\" or \"?31..327\" -> remove the question mark\n",
    "    # if it's \"<1..106\" or \"22..>115\" -> remove the \"<\" or \">\" signs\n",
    "    if value == '?':\n",
    "        return -1\n",
    "    value = value.replace('?', '').replace('>', '').replace('<', '')\n",
    "    return int(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def extract_positions(posit_string):\n",
    "    \"\"\"\n",
    "    Extract isoform_id(str) and start/end positions(int, int/float) of any feature key from the string \n",
    "    \"\"\"\n",
    "    isoform = ''\n",
    "    start = end = np.nan\n",
    "    if '..' in posit_string:\n",
    "        start, end = posit_string.split('..')\n",
    "    if ':' in posit_string:\n",
    "        if isinstance(start, str):\n",
    "            isoform, start = start.split(':')\n",
    "        else:\n",
    "            isoform, start = posit_string.split(':')\n",
    "    # in the case when we have only one numeric value as a posit_string\n",
    "    if isinstance(start, float):\n",
    "        start = posit_string\n",
    "    # change the type of start and end into int/float(np.nan)\n",
    "    if isinstance(start, str):\n",
    "        start = resolve_unclear_position(start)\n",
    "    if isinstance(end, str):\n",
    "        end = resolve_unclear_position(end)\n",
    "    return isoform, start, end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def preprocess_uniprot(path_to_file):\n",
    "    \"\"\"\n",
    "    A complex complete function to preprocess Uniprot data from specifying the path to the flat text file \n",
    "    to the returning a dataframe containing information about:\n",
    "        - protein_id(str)\n",
    "        - feature(category)\n",
    "        - isoform_od(str)\n",
    "        - start(int)\n",
    "        - end(int)\n",
    "        - note information(str)\n",
    "    \"\"\"\n",
    "    all_data = []\n",
    "    with open(path_to_file) as f:\n",
    "        \n",
    "        is_splitted = False\n",
    "        new_instance = False\n",
    "        combined_note = []\n",
    "\n",
    "        for line in f:\n",
    "\n",
    "            if line.startswith(('AC', 'FT')):\n",
    "                if is_splitted:\n",
    "                    # in case when the note information is splitted into several lines\n",
    "                    if line.rstrip().endswith('\"'):\n",
    "                        # if it's the final part of the note\n",
    "                        combined_note.extend(extract_note_end(line))\n",
    "                        all_data.append([protein_id, feature, isoform, start, end, \" \".join(combined_note)])\n",
    "                        is_splitted = False\n",
    "                        new_instance = False\n",
    "                    else:\n",
    "                        # if it's the middle part of the note\n",
    "                        combined_note.extend(extract_note_end(line, has_mark=False))\n",
    "                elif line.startswith('AC'):\n",
    "                    # contains the protein_id information\n",
    "                    protein_id = line.split()[1].replace(';', '')\n",
    "                elif line.startswith('FT'):\n",
    "                    # contains all modifications/preprocessing events/etc., their positions, notes\n",
    "                    data = line.split()\n",
    "                    if data[1].isupper() and not data[1].startswith('ECO'):\n",
    "                            feature = data[1]\n",
    "                            isoform, start, end = extract_positions(data[2])\n",
    "                            new_instance = True\n",
    "                    else:\n",
    "                        if data[1].startswith('/note'):\n",
    "                            note = extract_note(line)\n",
    "                            if note:\n",
    "                                # if note was created > it contains just one line and can be already added to the data \n",
    "                                all_data.append([protein_id, feature, isoform, start, end, note[0]])\n",
    "                                new_instance = False\n",
    "                            else:\n",
    "                                # if note is empty > it's splitted into several lines and we create combined_note\n",
    "                                combined_note = extract_note(line, splitted=True)\n",
    "                                is_splitted = True\n",
    "                        else:\n",
    "                            if new_instance:\n",
    "                                # in case when we don't have any note but need to add other information about instance\n",
    "                                all_data.append([protein_id, feature, isoform, start, end, ''])\n",
    "                                new_instance = False\n",
    "    \n",
    "    # create a dataframe for preprocessed data    \n",
    "    uniprot_df = pd.DataFrame(all_data, columns=['protein_id', 'feature', 'isoform_id', 'start', 'end', 'note'])\n",
    "    # change the dtypes of the columns\n",
    "    uniprot_df.feature = uniprot_df.feature.astype('category')\n",
    "    uniprot_df.end = uniprot_df.end.astype('Int64')\n",
    "    # to filter the instances that don't have a defined start/end position(start=-1 or end=-1)\n",
    "    uniprot_df = uniprot_df[(uniprot_df.start != -1) & (uniprot_df.end != -1)]\n",
    "    \n",
    "    return uniprot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "uniprot_df = preprocess_uniprot(path_downloaded_uniprot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1320214 entries, 0 to 1320213\n",
      "Data columns (total 6 columns):\n",
      "protein_id    1320214 non-null object\n",
      "feature       1320214 non-null object\n",
      "isoform_id    1320214 non-null object\n",
      "start         1320214 non-null int64\n",
      "end           908582 non-null float64\n",
      "note          1320214 non-null object\n",
      "dtypes: float64(1), int64(1), object(4)\n",
      "memory usage: 60.4+ MB\n"
     ]
    }
   ],
   "source": [
    "uniprot_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uniprot_df.to_csv('../testdata/preprocessed_uniprot_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export notebook to script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
